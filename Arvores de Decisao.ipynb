{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste notebook é implementar uma árvore de decisão do zero (numpy e pandas), que possuirá a seguinte API:\n",
    "\n",
    "```Python\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "tree = decision_tree_algorithm(train_df)\n",
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "```\n",
    "\n",
    "Se der tempo, colocar diagrama do algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impotar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar e preparar os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formato dos dados\n",
    "- Nesse caso, a última coluna do dataset é o atributo alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Iris.csv\")\n",
    "df = df.drop(\"Id\", axis=1)\n",
    "df = df.rename(columns={\"species\": \"label\"})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão de treino e teste\n",
    "\n",
    "Como as classes estão distruídas igualmente, não precisamos realizar a amostragem estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param test_size can be an integer or float (percentage) of the dataset size.\n",
    "def train_test_split(df, test_size):\n",
    "    \n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    # extract all indexes from dataset\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_df, test_df = train_test_split(df, test_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções auxiliares\n",
    "\n",
    "As funções auxiliares irão trabalhar com NumPy arrays. Logo, iremos atribuir os valores no formato numpy a uma variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.values\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O conjunto ou subconjunto de dados está puro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is only one class on target column\n",
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação\n",
    "\n",
    "Definida pela moda em um problema de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potenciais divisões\n",
    "\n",
    "Utilizada para extrair os possíveis valores para os ramos das árvores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):          # excluding the last column which is the label\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos dados\n",
    "\n",
    "Funciona com dados categóricos ou numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        left = data[split_column_values <= split_value]\n",
    "        right = data[split_column_values >  split_value]\n",
    "    \n",
    "    # feature is categorical   \n",
    "    else:\n",
    "        left = data[split_column_values == split_value]\n",
    "        right = data[split_column_values != split_value]\n",
    "    \n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Gain\n",
    "\n",
    "O cálculo de Information Gain permite selecionar a melhor divisão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info_gain_numeric(df, left, right, entropy_before_split, split_values):\n",
    "    \n",
    "    total_elements = df.shape[0]\n",
    "    ent_left = calc_entropy(left)\n",
    "    \n",
    "    ent_right = calc_entropy(right)\n",
    "    \n",
    "    weighted_entropy = ((left.shape[0] / total_elements) * ent_left) + (\n",
    "        (right.shape[0] / total_elements) * ent_right\n",
    "    )\n",
    "    info_gain = entropy_before_split - weighted_entropy\n",
    "    \n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    best_information_gain = -9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_left, data_right = split_data(data, split_column=column_index, split_value=value)\n",
    "            information_gain = calc_info_gain_numeric(data, data_left, data_right, calculate_entropy(data), value)\n",
    "            \n",
    "            if information_gain >= best_information_gain:\n",
    "                best_information_gain = information_gain\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo da Árvore de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representação da árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tree = {\"question\": [\"yes_answer\", \n",
    "                         \"no_answer\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tree = {\"petal_width <= 0.8\": [\"Iris-setosa\", \n",
    "                                      {\"petal_width <= 1.65\": [{\"petal_length <= 4.9\": [\"Iris-versicolor\", \n",
    "                                                                                        \"Iris-virginica\"]}, \n",
    "                                                                \"Iris-virginica\"]}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinar o tipo de atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=5):\n",
    "    \n",
    "    # Data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # Stop condition\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_left, data_right = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # check for empty data\n",
    "        if len(data_left) == 0 or len(data_right) == 0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "        \n",
    "        # determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            \n",
    "        # feature is categorical\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_left, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_right, counter, min_samples, max_depth)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the question.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = decision_tree_algorithm(train_df, max_depth=3)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = test_df.iloc[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":  # feature is continuous\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # leaft node\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_example(example, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "\n",
    "    df[\"classification\"] = df.apply(classify_example, axis=1, args=(tree,))\n",
    "    df[\"classification_correct\"] = df[\"classification\"] == df[\"label\"]\n",
    "    \n",
    "    accuracy = df[\"classification_correct\"].mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = calculate_accuracy(train_df, tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree as SKTree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SKTree.DecisionTreeClassifier(max_depth=3)\n",
    "clf = clf.fit(train_df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']], train_df['label'])\n",
    "\n",
    "print(f\"Train accuracy = {accuracy_score(train_df['label'],  clf.predict( train_df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']] ) )}\")\n",
    "print(f\"Test accuracy = {accuracy_score(test_df['label'],  clf.predict( test_df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']] ) )}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(tree, width=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKTree.plot_tree(clf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar árvore gerada pelo sklearn em PDF\n",
    "\n",
    "import graphviz \n",
    "dot_data = SKTree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"iris\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
